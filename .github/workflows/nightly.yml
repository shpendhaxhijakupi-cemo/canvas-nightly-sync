name: Nightly Canvas Export (Cohorts)

on:
  workflow_dispatch:          # allow manual runs
  schedule:
    - cron: "0 5 * * *"       # daily at 05:00 UTC

permissions:
  contents: read

jobs:
  run-export:
    runs-on: ubuntu-24.04
    strategy:
      fail-fast: false
      matrix:
        include:
          # ---- B2C split into two chunks (no soft-delete here) ----
          - key: B2C_P1
            table: "B2C Courses Enrollment"
            soft_delete: "false"
          - key: B2C_P2
            table: "B2C Courses Enrollment"
            soft_delete: "false"

          # ---- Other cohorts (with soft-delete) ----
          - key: SOUTHLANDS
            table: "Southlands Courses Enrollment"
            soft_delete: "true"
          - key: PHOENIX
            table: "Phoenix Christian Courses Enrollment"
            soft_delete: "true"
          - key: ONE_TWO_ONE_ONE
            table: "1211 Courses Enrollment"
            soft_delete: "true"
          - key: ROCKCHRISTIAN
            table: "Rock Christian Courses Enrollment"
            soft_delete: "true"
          - key: GANEVAS
            table: "Ganevas Courses Enrollment"
            soft_delete: "true"
          - key: NHCC
            table: "NHCC Courses Enrollment"
            soft_delete: "true"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      # Map cohort -> the right Canvas ID secret
      - name: Resolve Canvas IDs for cohort
        id: resolve_ids
        shell: bash
        env:
          INCLUDE_CANVAS_IDS_P1: ${{ secrets.INCLUDE_CANVAS_IDS_P1 }}
          INCLUDE_CANVAS_IDS_P2: ${{ secrets.INCLUDE_CANVAS_IDS_P2 }}
          IDS_SOUTHLANDS:        ${{ secrets.IDS_SOUTHLANDS }}
          IDS_PHOENIX:           ${{ secrets.IDS_PHOENIX }}
          IDS_1211:              ${{ secrets.IDS_1211 }}
          IDS_ROCKCHRISTIAN:     ${{ secrets.IDS_ROCKCHRISTIAN }}
          IDS_GANEVAS:           ${{ secrets.IDS_GANEVAS }}
          IDS_NHCC:              ${{ secrets.IDS_NHCC }}
        run: |
          case "${{ matrix.key }}" in
            B2C_P1)          echo "ids=$INCLUDE_CANVAS_IDS_P1" >> $GITHUB_OUTPUT ;;
            B2C_P2)          echo "ids=$INCLUDE_CANVAS_IDS_P2" >> $GITHUB_OUTPUT ;;
            SOUTHLANDS)      echo "ids=$IDS_SOUTHLANDS"        >> $GITHUB_OUTPUT ;;
            PHOENIX)         echo "ids=$IDS_PHOENIX"           >> $GITHUB_OUTPUT ;;
            ONE_TWO_ONE_ONE) echo "ids=$IDS_1211"              >> $GITHUB_OUTPUT ;;
            ROCKCHRISTIAN)   echo "ids=$IDS_ROCKCHRISTIAN"     >> $GITHUB_OUTPUT ;;
            GANEVAS)         echo "ids=$IDS_GANEVAS"           >> $GITHUB_OUTPUT ;;
            NHCC)            echo "ids=$IDS_NHCC"              >> $GITHUB_OUTPUT ;;
            *) echo "Unknown cohort key: ${{ matrix.key }}"; exit 1 ;;
          esac

      - name: Build per-course CSV for Airtable (${{ matrix.table }})
        env:
          API_URL: ${{ secrets.CANVAS_API_URL }}
          API_KEY: ${{ secrets.CANVAS_API_KEY }}
          IDS:     ${{ steps.resolve_ids.outputs.ids }}
        run: |
          python - <<'PY'
          import csv, os, time, sys
          from datetime import datetime
          import requests

          API_URL = os.environ["API_URL"].rstrip("/")
          API_KEY = os.environ["API_KEY"]
          IDS     = [s.strip() for s in (os.environ.get("IDS") or "").split(",") if s.strip()]
          HEADERS = {"Authorization": f"Bearer {API_KEY}"}
          PER_PAGE = 100
          START_MONTH = 8  # school year starts in August

          def iso(dt): return datetime.fromisoformat(dt.replace("Z","+00:00")) if dt else None
          def school_year(dt):
              if not dt: return ""
              y = dt.year
              return f"{y-1}-{y}" if dt.month < START_MONTH else f"{y}-{y+1}"

          def paged(url, params=None):
              params = dict(params or {})
              while True:
                  r = requests.get(url, headers=HEADERS, params=params, timeout=60)
                  if r.status_code in (429,500,502,503,504): time.sleep(1); continue
                  r.raise_for_status()
                  data = r.json()
                  if isinstance(data, list):
                      for x in data: yield x
                  else:
                      yield data
                  link = r.headers.get("Link","")
                  nxt = None
                  for part in link.split(","):
                      if 'rel="next"' in part:
                          nxt = part[part.find("<")+1: part.find(">")]
                          break
                  if not nxt: break
                  url, params = nxt, None

          out = "Canvas_Enrollment_Courses.csv"
          with open(out, "w", newline="", encoding="utf-8") as f:
              w = csv.writer(f)
              w.writerow([
                  "Enrollment Course Key","Enrollment Key","Student Canvas ID","Student Name",
                  "School Year","Course ID","Course Code","Course Name",
                  "Course Start Date","Course End Date","Assigned Teachers",
                  "Current Score","Final Score","Passed?",
                  "Total Assignments","Completed Assignments","Unsubmitted Assignments","% Completed"
              ])

              if not IDS:
                  print("[fatal] No Canvas IDs provided for this cohort.", file=sys.stderr)
                  sys.exit(1)

              # substring filters (case-insensitive)
              bad_patterns = ("NPS","feedback","survey")

              for uid in IDS:
                  try:
                      p = requests.get(f"{API_URL}/users/{uid}/profile", headers=HEADERS, timeout=30)
                      name = (p.json().get("name") or f"User {uid}") if p.ok else f"User {uid}"

                      for enr in paged(f"{API_URL}/users/{uid}/enrollments",
                                       {"type[]":"StudentEnrollment","include[]":"grades","per_page":PER_PAGE}):
                          cid = enr.get("course_id")
                          if not cid: continue
                          grades = enr.get("grades") or {}
                          cur = grades.get("current_score")
                          fin = grades.get("final_score")

                          c = requests.get(f"{API_URL}/courses/{cid}", headers=HEADERS, timeout=60)
                          course = c.json() if c.ok else {}
                          cstart = iso(course.get("start_at")) or iso(enr.get("start_at"))
                          cend   = iso(course.get("end_at")) or iso(enr.get("end_at"))
                          sy     = school_year(cstart or iso(enr.get("created_at"))) or "unknown"

                          # require all parts for a valid key
                          if not (str(uid).strip() and str(cid).strip() and sy != "unknown"):
                              print(f"[skip] bad key parts uid={uid} cid={cid} sy={sy}", file=sys.stderr)
                              continue

                          # teachers
                          tnames = []
                          for t in paged(f"{API_URL}/courses/{cid}/enrollments",
                                         {"type[]":"TeacherEnrollment","per_page":PER_PAGE}):
                              u = t.get("user") or {}
                              nm = u.get("name") or u.get("sortable_name")
                              if nm: tnames.append(nm)
                          teachers = ", ".join(sorted(set(tnames)))

                          # pass/fail
                          passed = ""
                          try:
                              if fin is not None: passed = "Yes" if float(fin) >= 60.0 else "No"
                          except Exception: passed = ""

                          # assignments:
                          # - include published
                          # - exclude exact "End of Unit Feedback (Mandatory)"
                          # - exclude names containing NPS|feedback|survey
                          total = comp = unsubmitted = 0
                          for a in paged(f"{API_URL}/courses/{cid}/assignments"):
                              name_a = (a.get("name") or "")
                              if not a.get("published"): continue
                              if name_a == "End of Unit Feedback (Mandatory)": continue
                              if any(patt.lower() in name_a.lower() for patt in bad_patterns): continue

                              total += 1
                              s = requests.get(
                                f"{API_URL}/courses/{cid}/assignments/{a['id']}/submissions/{uid}",
                                headers=HEADERS, timeout=30)
                              if s.ok:
                                  sub = s.json()
                                  state = sub.get("workflow_state") or "unsubmitted"
                                  if sub.get("excused"):
                                      comp += 1
                                  elif state in ("graded","submitted") and (sub.get("grade") not in (None,"-","")):
                                      comp += 1
                                  else:
                                      unsubmitted += 1
                              else:
                                  unsubmitted += 1

                          pct = f"{(comp/total*100):.2f}%" if total else "0.00%"

                          enr_key = f"{uid}-{sy}"
                          key     = f"{uid}-{sy}-{cid}"

                          w.writerow([
                              key, enr_key, uid, name,
                              sy, cid, course.get("course_code") or "", course.get("name") or "",
                              cstart.isoformat() if cstart else "",
                              cend.isoformat() if cend else "",
                              teachers,
                              cur if cur is not None else "",
                              fin if fin is not None else "",
                              passed, total, comp, unsubmitted, pct
                          ])
                  except Exception as e:
                      print(f"[warn] failed student {uid}: {e}", file=sys.stderr)
                      continue

          print("[ok] wrote Canvas_Enrollment_Courses.csv for cohort")
          PY

      - name: Prepare CSV for upsert (strip Enrollment Key)
        run: |
          python - <<'PY'
          import csv
          src = "Canvas_Enrollment_Courses.csv"
          dst = "Canvas_Enrollment_Courses_for_upsert.csv"
          with open(src, newline="", encoding="utf-8") as f, open(dst, "w", newline="", encoding="utf-8") as g:
              r = csv.DictReader(f)
              fields = [h for h in r.fieldnames if h != "Enrollment Key"]
              w = csv.DictWriter(g, fieldnames=fields)
              w.writeheader()
              for row in r:
                  row.pop("Enrollment Key", None)
                  w.writerow(row)
          print("[ok] wrote", dst)
          PY

      - name: Upload CSVs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: canvas-csvs-${{ matrix.key }}
          path: "*.csv"

      - name: Upsert Courses → Airtable (${{ matrix.table }})
        env:
          AIRTABLE_PAT:        ${{ secrets.AIRTABLE_PAT }}
          AIRTABLE_BASE_ID:    ${{ secrets.AIRTABLE_BASE_ID }}
          AIRTABLE_TABLE_NAME: ${{ matrix.table }}
        run: |
          echo "Upserting into Airtable table: $AIRTABLE_TABLE_NAME"
          python - <<'PY'
          import os, csv, requests, time, sys, json

          base  = os.environ["AIRTABLE_BASE_ID"]
          table = os.environ["AIRTABLE_TABLE_NAME"]
          token = os.environ["AIRTABLE_PAT"]
          api   = f"https://api.airtable.com/v0/{base}/{requests.utils.quote(table, safe='')}"
          hdr   = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}

          rows = []
          with open("Canvas_Enrollment_Courses_for_upsert.csv", newline="", encoding="utf-8") as f:
              rows = list(csv.DictReader(f))

          # merge‑upsert in batches of 10 via 'Enrollment Course Key'
          for i in range(0, len(rows), 10):
              batch = rows[i:i+10]
              payload = {
                "performUpsert": {"fieldsToMergeOn": ["Enrollment Course Key"]},
                "records": [{"fields": r} for r in batch]
              }
              r = requests.post(api, headers=hdr, data=json.dumps(payload), timeout=60)
              if r.status_code in (429,500,502,503,504):
                  time.sleep(2); r = requests.post(api, headers=hdr, data=json.dumps(payload), timeout=60)
              r.raise_for_status()
          print("[ok] upserted", len(rows), "rows")
          PY

      - name: Mark missing records as inactive (soft-delete)
        if: ${{ matrix.soft_delete != 'false' }}
        env:
          AIRTABLE_PAT:        ${{ secrets.AIRTABLE_PAT }}
          AIRTABLE_BASE_ID:    ${{ secrets.AIRTABLE_BASE_ID }}
          AIRTABLE_TABLE_NAME: ${{ matrix.table }}
        run: |
          python - <<'PY'
          import os, csv, requests, time, sys

          BASE  = os.environ["AIRTABLE_BASE_ID"]
          TABLE = os.environ["AIRTABLE_TABLE_NAME"]
          TOKEN = os.environ["AIRTABLE_PAT"]
          API   = f"https://api.airtable.com/v0/{BASE}/{requests.utils.quote(TABLE, safe='')}"
          H     = {"Authorization": f"Bearer {TOKEN}"}

          # Current keys from CSV
          current_keys = set()
          with open("Canvas_Enrollment_Courses_for_upsert.csv", newline="", encoding="utf-8") as f:
            for r in csv.DictReader(f):
              k = (r.get("Enrollment Course Key") or "").strip()
              if k: current_keys.add(k)

          # Fetch all existing (id, key)
          existing = []
          offset = None
          while True:
            params = {"pageSize": 100}
            if offset: params["offset"] = offset
            r = requests.get(API, headers=H, params=params, timeout=60)
            r.raise_for_status()
            j = r.json()
            for rec in j.get("records", []):
              fields = rec.get("fields", {})
              key = (fields.get("Enrollment Course Key") or "").strip()
              if key:
                existing.append((rec["id"], key))
            offset = j.get("offset")
            if not offset:
              break

          to_mark = [rid for rid, key in existing if key not in current_keys]
          print(f"[info] Existing: {len(existing)}, Current: {len(current_keys)}, Inactive to mark: {len(to_mark)}")

          try:
            for i in range(0, len(to_mark), 10):
              batch = [{"id": rid, "fields": {"Active": False}} for rid in to_mark[i:i+10]]
              r = requests.patch(API, headers={**H, "Content-Type":"application/json"},
                                 json={"records": batch, "typecast": True}, timeout=60)
              if r.status_code in (429,500,502,503,504):
                time.sleep(2)
                r = requests.patch(API, headers={**H, "Content-Type":"application/json"},
                                   json={"records": batch, "typecast": True}, timeout=60)
              r.raise_for_status()
            print("[ok] soft-delete complete")
          except requests.HTTPError as e:
            print(f"[warn] Soft-delete skipped for table '{TABLE}': {e}. "
                  f"Add an 'Active' checkbox field to enable soft-delete.")
            sys.exit(0)
          PY

  # ---- Final union soft-delete for B2C table (after both chunks finish) ----
  softdelete-b2c:
    needs: run-export
    runs-on: ubuntu-24.04
    steps:
      - name: Download B2C P1 CSV
        uses: actions/download-artifact@v4
        with:
          name: canvas-csvs-B2C_P1
          path: b2c-p1

      - name: Download B2C P2 CSV
        uses: actions/download-artifact@v4
        with:
          name: canvas-csvs-B2C_P2
          path: b2c-p2

      - name: Union soft-delete for B2C
        env:
          AIRTABLE_PAT:     ${{ secrets.AIRTABLE_PAT }}
          AIRTABLE_BASE_ID: ${{ secrets.AIRTABLE_BASE_ID }}
        run: |
          python - <<'PY'
          import os, csv, requests, time, sys

          TABLE = "B2C Courses Enrollment"
          BASE  = os.environ["AIRTABLE_BASE_ID"]
          TOKEN = os.environ["AIRTABLE_PAT"]
          API   = f"https://api.airtable.com/v0/{BASE}/{requests.utils.quote(TABLE, safe='')}"
          H     = {"Authorization": f"Bearer {TOKEN}"}

          # 1) union of keys from all chunk CSVs
          keyset = set()
          for folder in ("b2c-p1","b2c-p2"):
              if not os.path.isdir(folder):
                  continue
              for name in os.listdir(folder):
                  if name.endswith(".csv"):
                      with open(os.path.join(folder, name), newline="", encoding="utf-8") as f:
                          for r in csv.DictReader(f):
                              k = (r.get("Enrollment Course Key") or "").strip()
                              if k: keyset.add(k)
          print(f"[info] union keys: {len(keyset)}")
          if not keyset:
              print("[warn] No keys found from B2C chunks; skipping soft-delete.")
              sys.exit(0)

          # 2) fetch existing records
          existing = []
          offset = None
          while True:
              params = {"pageSize": 100}
              if offset: params["offset"] = offset
              r = requests.get(API, headers=H, params=params, timeout=60); r.raise_for_status()
              j = r.json()
              for rec in j.get("records", []):
                  k = (rec.get("fields",{}).get("Enrollment Course Key") or "").strip()
                  if k: existing.append((rec["id"], k))
              offset = j.get("offset")
              if not offset: break

          # 3) mark inactive where key not in union
          to_mark = [rid for rid, k in existing if k not in keyset]
          print(f"[info] inactive to mark: {len(to_mark)}")
          for i in range(0, len(to_mark), 10):
              batch = [{"id": rid, "fields": {"Active": False}} for rid in to_mark[i:i+10]]
              r = requests.patch(API, headers={**H, "Content-Type":"application/json"},
                                 json={"records": batch, "typecast": True}, timeout=60)
              if r.status_code in (429,500,502,503,504):
                  time.sleep(2)
                  r = requests.patch(API, headers={**H, "Content-Type":"application/json"},
                                     json={"records": batch, "typecast": True}, timeout=60)
              r.raise_for_status()
          print("[ok] B2C union soft-delete complete")
          PY
